# ComparaÃ§Ã£o de Modelos Preditivos para o Mercado ImobiliÃ¡rio (Dataset house_16H)

Este repositÃ³rio contÃ©m os cÃ³digos e anÃ¡lises desenvolvidos para a disciplina de **MineraÃ§Ã£o de Dados Aplicada** do Centro de InformÃ¡tica da Universidade Federal de Pernambuco (CIn-UFPE).

O projeto realiza um estudo comparativo de diversos algoritmos de aprendizado de mÃ¡quina para classificar o potencial de investimentos imobiliÃ¡rios nos EUA.

## ğŸ‘¥ Autores
* Douglas AraÃºjo
* Hallan Ã‚ngelo
* Ingrid Freire
* Katharian Abrahel

## ğŸ“„ DescriÃ§Ã£o do Projeto

O objetivo deste trabalho Ã© aplicar e comparar modelos preditivos capazes de estimar o potencial de investimentos em regiÃµes de habitaÃ§Ãµes com base em dados demogrÃ¡ficos e do mercado imobiliÃ¡rio.

Foi utilizada a base de dados **house_16H**, que contÃ©m variÃ¡veis demogrÃ¡ficas e de mercado. O problema foi modelado como uma tarefa de classificaÃ§Ã£o binÃ¡ria (Investimento Positivo 'P' vs. Negativo 'N').

### Metodologia de AvaliaÃ§Ã£o
* **DivisÃ£o dos Dados:** 80% Treino / 20% Teste (Estratificado para manter proporÃ§Ã£o das classes).
* **ValidaÃ§Ã£o:** ValidaÃ§Ã£o Cruzada Estratificada (k=10).
* **OtimizaÃ§Ã£o:** Busca de hiperparÃ¢metros (RandomizedSearchCV) com 20 iteraÃ§Ãµes.
* **MÃ©tricas:** AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score e AUC-ROC.

## ğŸš€ Modelos Implementados

Os seguintes algoritmos foram implementados e otimizados em notebooks individuais:

1.  **KNN (K-Nearest Neighbors):** Otimizado para k=41, mÃ©trica Manhattan.
2.  **LVQ (Learning Vector Quantization):** ProtÃ³tipos por classe e ajuste de learning rate.
3.  **Ãrvore de DecisÃ£o:** CritÃ©rio de entropia com poda (max_depth=7).
4.  **SVM (Support Vector Machine):** Kernel RBF com ajuste de Gamma e C.
5.  **Random Forest:** Ensemble com 200 Ã¡rvores (bootstrap=True).
6.  **MLP (Multilayer Perceptron):** Rede neural com otimizador Adam e ativaÃ§Ã£o ReLU.
7.  **ComitÃª de Redes Neurais:** Voting Classifier com 3 melhores arquiteturas de RNA.
8.  **ComitÃª HeterogÃªneo (Stacking):** Random Forest, MLP e KNN como base; Random Forest como meta-aprendiz.
9.  **XGBoost:** Boosting baseado em gradiente otimizado.
10. **LightGBM:** Boosting baseado em histogramas (Crescimento folha-a-folha).

## ğŸ“Š Resultados Consolidados (Conjunto de Teste)

Abaixo, a performance comparativa dos modelos no conjunto de teste:

| Modelo | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **KNN** | 0.7547 | 0.7959 | 0.8754 | 0.8338 | 0.7825 |
| **LVQ** | 0.7762 | 0.8589 | 0.8155 | 0.8558 | 0.7493 |
| **Ãrvore de DecisÃ£o** | 0.8571 | 0.8917 | 0.9070 | 0.8992 | 0.9117 |
| **SVM** | 0.7356 | 0.7376 | 0.9682 | 0.8373 | 0.7905 |
| **Random Forest** | 0.8971 | 0.9158 | 0.9401 | 0.9277 | 0.9528 |
| **MLP** | 0.8944 | 0.9170 | 0.9344 | 0.9256 | 0.9471 |
| **ComitÃª de RNAs** | 0.7762 | 0.7846 | 0.9394 | 0.8551 | 0.8565 |
| **Stacking** | 0.8670 | 0.9082 | 0.9020 | 0.9051 | 0.9286 |
| **XGBoost** | 0.8964 | 0.9213 | 0.9323 | 0.9268 | 0.9525 |
| **LightGBM** | **0.9026** | **0.9225** | **0.9404** | **0.9314** | **0.9565** |

> **ConclusÃ£o:** O **LightGBM** apresentou o melhor desempenho geral, combinando a maior acurÃ¡cia (90,26%) e AUC-ROC (95,65%) com eficiÃªncia computacional, seguido de perto pelo Random Forest e XGBoost.

## ğŸ“‚ Estrutura do RepositÃ³rio

```bash
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ house_16H.arff
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ train.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_separacao_bases.ipynb
â”‚   â”œâ”€â”€ 02_knn.ipynb
â”‚   â”œâ”€â”€ 03_lvq.ipynb
â”‚   â”œâ”€â”€ 04_arvore_decisao.ipynb
â”‚   â”œâ”€â”€ 05_svm.ipynb
â”‚   â”œâ”€â”€ 06_random_forest.ipynb
â”‚   â”œâ”€â”€ 07_mlp.ipynb
â”‚   â”œâ”€â”€ 08_comite_rna.ipynb
â”‚   â”œâ”€â”€ 09_stacking.ipynb
â”‚   â”œâ”€â”€ 10_xgboost.ipynb
â”‚   â””â”€â”€ 11_lightgbm.ipynb
â””â”€â”€ README.md
```

## ğŸ› ï¸ Tecnologias Utilizadas

* Python
* Scikit-Learn
* XGBoost
* LightGBM
* Pandas / Numpy
* Matplotlib / Seaborn (VisualizaÃ§Ã£o)

## ğŸ“š ReferÃªncias

* Dataset house_16H (OpenML)
* DocumentaÃ§Ã£o do Scikit-Learn
* RelatÃ³rio TÃ©cnico da disciplina (MarÃ§o, 2025)
